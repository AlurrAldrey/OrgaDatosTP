{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../train.csv')\n",
    "df_test = pd.read_csv('../test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['keyword', 'location'], axis=1, inplace=True)\n",
    "df_test.drop(['keyword', 'location'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x = df['text']\n",
    "df_y = df['target']\n",
    "\n",
    "df_test_x = df_test['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vamos a probar distintos word-embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import TaggedDocument, Doc2Vec\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn import utils as skl_utils\n",
    "from tqdm import tqdm\n",
    "\n",
    "import multiprocessing\n",
    "import numpy as np\n",
    "\n",
    "class Doc2VecTransformer(BaseEstimator):\n",
    "\n",
    "    def __init__(self, vector_size=300, learning_rate=0.1, epochs=20):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epochs = epochs\n",
    "        self._model = None\n",
    "        self.vector_size = vector_size\n",
    "        self.workers = multiprocessing.cpu_count() - 1\n",
    "\n",
    "    def fit(self, df_x, df_y=None):\n",
    "        tagged_x = [TaggedDocument(clean_text(row).split(), [index]) for index, row in enumerate(df_x)]\n",
    "        model = Doc2Vec(documents=tagged_x, vector_size=self.vector_size, workers=self.workers)\n",
    "\n",
    "        for epoch in range(self.epochs):\n",
    "            model.train(skl_utils.shuffle([x for x in tqdm(tagged_x)]), total_examples=len(tagged_x), epochs=1)\n",
    "            model.alpha -= self.learning_rate\n",
    "            model.min_alpha = model.alpha\n",
    "\n",
    "        self._model = model\n",
    "        return self\n",
    "\n",
    "    def transform(self, df_x):\n",
    "        return np.asmatrix(np.array([self._model.infer_vector(clean_text(row).split())\n",
    "                                     for index, row in enumerate(df_x)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7613/7613 [00:00<00:00, 4287222.93it/s]\n",
      "100%|██████████| 7613/7613 [00:00<00:00, 4281474.44it/s]\n",
      "100%|██████████| 7613/7613 [00:00<00:00, 4542785.08it/s]\n",
      "100%|██████████| 7613/7613 [00:00<00:00, 3356942.43it/s]\n",
      "100%|██████████| 7613/7613 [00:00<00:00, 3925649.91it/s]\n",
      "100%|██████████| 7613/7613 [00:00<00:00, 4460292.83it/s]\n",
      "100%|██████████| 7613/7613 [00:00<00:00, 4507515.01it/s]\n",
      "100%|██████████| 7613/7613 [00:00<00:00, 4266030.24it/s]\n",
      "100%|██████████| 7613/7613 [00:00<00:00, 3826849.99it/s]\n",
      "100%|██████████| 7613/7613 [00:00<00:00, 3146864.72it/s]\n",
      "100%|██████████| 7613/7613 [00:00<00:00, 4296452.68it/s]\n",
      "100%|██████████| 7613/7613 [00:00<00:00, 4464034.16it/s]\n",
      "100%|██████████| 7613/7613 [00:00<00:00, 2935665.75it/s]\n",
      "100%|██████████| 7613/7613 [00:00<00:00, 888484.27it/s]\n",
      "100%|██████████| 7613/7613 [00:00<00:00, 1828926.99it/s]\n",
      "100%|██████████| 7613/7613 [00:00<00:00, 2283575.51it/s]\n",
      "100%|██████████| 7613/7613 [00:00<00:00, 4567477.66it/s]\n",
      "100%|██████████| 7613/7613 [00:00<00:00, 4609012.18it/s]\n",
      "100%|██████████| 7613/7613 [00:00<00:00, 4509424.71it/s]\n",
      "100%|██████████| 7613/7613 [00:00<00:00, 4213119.98it/s]\n",
      "100%|██████████| 3263/3263 [00:00<00:00, 1768218.86it/s]\n",
      "100%|██████████| 3263/3263 [00:00<00:00, 3458684.34it/s]\n",
      "100%|██████████| 3263/3263 [00:00<00:00, 4138498.32it/s]\n",
      "100%|██████████| 3263/3263 [00:00<00:00, 2688804.31it/s]\n",
      "100%|██████████| 3263/3263 [00:00<00:00, 1769819.47it/s]\n",
      "100%|██████████| 3263/3263 [00:00<00:00, 3537351.76it/s]\n",
      "100%|██████████| 3263/3263 [00:00<00:00, 3544681.16it/s]\n",
      "100%|██████████| 3263/3263 [00:00<00:00, 4080505.05it/s]\n",
      "100%|██████████| 3263/3263 [00:00<00:00, 3927120.22it/s]\n",
      "100%|██████████| 3263/3263 [00:00<00:00, 2647198.06it/s]\n",
      "100%|██████████| 3263/3263 [00:00<00:00, 4090261.19it/s]\n",
      "100%|██████████| 3263/3263 [00:00<00:00, 3442156.43it/s]\n",
      "100%|██████████| 3263/3263 [00:00<00:00, 2612831.99it/s]\n",
      "100%|██████████| 3263/3263 [00:00<00:00, 2790785.88it/s]\n",
      "100%|██████████| 3263/3263 [00:00<00:00, 3326692.74it/s]\n",
      "100%|██████████| 3263/3263 [00:00<00:00, 4087817.79it/s]\n",
      "100%|██████████| 3263/3263 [00:00<00:00, 3215698.77it/s]\n",
      "100%|██████████| 3263/3263 [00:00<00:00, 3659362.02it/s]\n",
      "100%|██████████| 3263/3263 [00:00<00:00, 4097608.97it/s]\n",
      "100%|██████████| 3263/3263 [00:00<00:00, 3919247.98it/s]\n"
     ]
    }
   ],
   "source": [
    "doc2vec_trf = Doc2VecTransformer()\n",
    "\n",
    "doc2vec_features = doc2vec_trf.fit(df_x).transform(df_x)\n",
    "\n",
    "test_doc2vec_features = doc2vec_trf.fit(df_test_x).transform(df_test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(doc2vec_features, df_y, test_size=.1, random_state=42)\n",
    "\n",
    "import xgboost as xgb\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "\n",
    "def f1_eval(y_pred, dtrain):\n",
    "    y_true = dtrain.get_label()\n",
    "    f1_score_value = f1_score(y_true, np.round(y_pred))\n",
    "    return 'f1_score', f1_score_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    # Parameters that we are going to tune.\n",
    "    'max_depth':6,\n",
    "    'min_child_weight': 1,\n",
    "    'eta':.1,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 1,\n",
    "    # Other parameters\n",
    "    'objective':'binary:logistic',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tTest-error:0.46063\tTest-f1_score:0.13333\n",
      "Multiple eval metrics have been passed: 'Test-f1_score' will be used for early stopping.\n",
      "\n",
      "Will train until Test-f1_score hasn't improved in 10 rounds.\n",
      "[1]\tTest-error:0.47900\tTest-f1_score:0.26263\n",
      "[2]\tTest-error:0.46457\tTest-f1_score:0.25000\n",
      "[3]\tTest-error:0.46457\tTest-f1_score:0.25000\n",
      "[4]\tTest-error:0.48688\tTest-f1_score:0.21895\n",
      "[5]\tTest-error:0.48819\tTest-f1_score:0.21849\n",
      "[6]\tTest-error:0.49475\tTest-f1_score:0.21294\n",
      "[7]\tTest-error:0.48556\tTest-f1_score:0.21277\n",
      "[8]\tTest-error:0.46719\tTest-f1_score:0.24576\n",
      "[9]\tTest-error:0.45800\tTest-f1_score:0.24946\n",
      "[10]\tTest-error:0.47244\tTest-f1_score:0.23404\n",
      "[11]\tTest-error:0.46325\tTest-f1_score:0.23427\n",
      "Stopping. Best iteration:\n",
      "[1]\tTest-error:0.47900\tTest-f1_score:0.26263\n",
      "\n",
      "Best F1 score: 0.26 with 2 rounds\n"
     ]
    }
   ],
   "source": [
    "model = xgb.train(\n",
    "    params,\n",
    "    dtrain,\n",
    "    num_boost_round=1000,\n",
    "    evals=[(dtest, \"Test\")],\n",
    "    early_stopping_rounds=10,\n",
    "    feval=f1_eval,\n",
    "    maximize=True\n",
    ")\n",
    "\n",
    "print(\"Best F1 score: {:.2f} with {} rounds\".format(\n",
    "                 model.best_score,\n",
    "                 model.best_iteration+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Doc2Vec with text cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gensim to pre process text\n",
    "from gensim import utils\n",
    "import gensim.parsing.preprocessing as gsp\n",
    "\n",
    "filters = [ \n",
    "           gsp.strip_punctuation,\n",
    "           gsp.strip_multiple_whitespaces,\n",
    "           gsp.stem_text\n",
    "          ]\n",
    "\n",
    "def clean_text(s):\n",
    "    s = s.lower()\n",
    "    s = utils.to_unicode(s)\n",
    "    for f in filters:\n",
    "        s = f(s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x_cleaned = df_x.apply(lambda x: clean_text(x))\n",
    "df_test_x_cleaned = df_test_x.apply(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7613/7613 [00:00<00:00, 973542.98it/s]\n",
      "100%|██████████| 7613/7613 [00:00<00:00, 4450346.53it/s]\n",
      "100%|██████████| 7613/7613 [00:00<00:00, 4459669.88it/s]\n",
      "100%|██████████| 7613/7613 [00:00<00:00, 3248015.09it/s]\n",
      "100%|██████████| 7613/7613 [00:00<00:00, 907730.52it/s]\n",
      "100%|██████████| 7613/7613 [00:00<00:00, 902981.63it/s]\n",
      "100%|██████████| 7613/7613 [00:00<00:00, 929260.12it/s]\n",
      "100%|██████████| 7613/7613 [00:00<00:00, 4706151.27it/s]\n",
      "100%|██████████| 7613/7613 [00:00<00:00, 4637797.58it/s]\n",
      "100%|██████████| 7613/7613 [00:00<00:00, 4295874.66it/s]\n",
      "100%|██████████| 7613/7613 [00:00<00:00, 927775.12it/s]\n",
      "100%|██████████| 7613/7613 [00:00<00:00, 949345.51it/s]\n",
      "100%|██████████| 7613/7613 [00:00<00:00, 926348.60it/s]\n",
      "100%|██████████| 7613/7613 [00:00<00:00, 4275741.34it/s]\n",
      "100%|██████████| 7613/7613 [00:00<00:00, 4267170.43it/s]\n",
      "100%|██████████| 7613/7613 [00:00<00:00, 2145195.59it/s]\n",
      "100%|██████████| 7613/7613 [00:00<00:00, 1395962.07it/s]\n",
      "100%|██████████| 7613/7613 [00:00<00:00, 4562256.94it/s]\n",
      "100%|██████████| 7613/7613 [00:00<00:00, 4282622.90it/s]\n",
      "100%|██████████| 7613/7613 [00:00<00:00, 4363382.94it/s]\n",
      "100%|██████████| 3263/3263 [00:00<00:00, 2809692.87it/s]\n",
      "100%|██████████| 3263/3263 [00:00<00:00, 3549277.48it/s]\n",
      "100%|██████████| 3263/3263 [00:00<00:00, 2727384.21it/s]\n",
      "100%|██████████| 3263/3263 [00:00<00:00, 3017864.16it/s]\n",
      "100%|██████████| 3263/3263 [00:00<00:00, 4123535.39it/s]\n",
      "100%|██████████| 3263/3263 [00:00<00:00, 3113287.98it/s]\n",
      "100%|██████████| 3263/3263 [00:00<00:00, 3152006.90it/s]\n",
      "100%|██████████| 3263/3263 [00:00<00:00, 3013213.11it/s]\n",
      "100%|██████████| 3263/3263 [00:00<00:00, 3375095.92it/s]\n",
      "100%|██████████| 3263/3263 [00:00<00:00, 3597795.47it/s]\n",
      "100%|██████████| 3263/3263 [00:00<00:00, 3289116.55it/s]\n",
      "100%|██████████| 3263/3263 [00:00<00:00, 2750404.73it/s]\n",
      "100%|██████████| 3263/3263 [00:00<00:00, 3380097.30it/s]\n",
      "100%|██████████| 3263/3263 [00:00<00:00, 3454319.52it/s]\n",
      "100%|██████████| 3263/3263 [00:00<00:00, 4159882.66it/s]\n",
      "100%|██████████| 3263/3263 [00:00<00:00, 4082939.72it/s]\n",
      "100%|██████████| 3263/3263 [00:00<00:00, 3620638.61it/s]\n",
      "100%|██████████| 3263/3263 [00:00<00:00, 2718715.52it/s]\n",
      "100%|██████████| 3263/3263 [00:00<00:00, 1143455.09it/s]\n",
      "100%|██████████| 3263/3263 [00:00<00:00, 3042688.74it/s]\n"
     ]
    }
   ],
   "source": [
    "doc2vec_trf = Doc2VecTransformer()\n",
    "\n",
    "doc2vec_features = doc2vec_trf.fit(df_x_cleaned).transform(df_x_cleaned)\n",
    "\n",
    "test_doc2vec_features = doc2vec_trf.fit(df_test_x_cleaned).transform(df_test_x_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(doc2vec_features, df_y, test_size=.1, random_state=42)\n",
    "\n",
    "import xgboost as xgb\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tTest-error:0.48556\tTest-f1_score:0.35986\n",
      "Multiple eval metrics have been passed: 'Test-f1_score' will be used for early stopping.\n",
      "\n",
      "Will train until Test-f1_score hasn't improved in 10 rounds.\n",
      "[1]\tTest-error:0.46325\tTest-f1_score:0.35701\n",
      "[2]\tTest-error:0.44619\tTest-f1_score:0.35361\n",
      "[3]\tTest-error:0.43176\tTest-f1_score:0.37807\n",
      "[4]\tTest-error:0.45538\tTest-f1_score:0.32621\n",
      "[5]\tTest-error:0.46588\tTest-f1_score:0.28571\n",
      "[6]\tTest-error:0.47244\tTest-f1_score:0.26829\n",
      "[7]\tTest-error:0.46063\tTest-f1_score:0.27629\n",
      "[8]\tTest-error:0.47244\tTest-f1_score:0.23077\n",
      "[9]\tTest-error:0.47769\tTest-f1_score:0.23529\n",
      "[10]\tTest-error:0.47244\tTest-f1_score:0.24686\n",
      "[11]\tTest-error:0.47769\tTest-f1_score:0.25103\n",
      "[12]\tTest-error:0.47113\tTest-f1_score:0.26283\n",
      "[13]\tTest-error:0.46850\tTest-f1_score:0.26694\n",
      "Stopping. Best iteration:\n",
      "[3]\tTest-error:0.43176\tTest-f1_score:0.37807\n",
      "\n",
      "Best F1 score: 0.38 with 4 rounds\n"
     ]
    }
   ],
   "source": [
    "model = xgb.train(\n",
    "    params,\n",
    "    dtrain,\n",
    "    num_boost_round=1000,\n",
    "    evals=[(dtest, \"Test\")],\n",
    "    early_stopping_rounds=10,\n",
    "    feval=f1_eval,\n",
    "    maximize=True\n",
    ")\n",
    "\n",
    "print(\"Best F1 score: {:.2f} with {} rounds\".format(\n",
    "                 model.best_score,\n",
    "                 model.best_iteration+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HP Tuning with Grid-Search and K-fold CV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tune Complexity of decision trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV with max_depth=3, min_child_weight=1\n",
      "\tMAE 0.48887080000000005 for 41 rounds, train-mae-mean: 0.4551996\n",
      "CV with max_depth=3, min_child_weight=2\n",
      "\tMAE 0.486352 for 125 rounds, train-mae-mean: 0.4010116\n",
      "CV with max_depth=3, min_child_weight=3\n",
      "\tMAE 0.4877488 for 78 rounds, train-mae-mean: 0.42977419999999994\n",
      "CV with max_depth=4, min_child_weight=1\n",
      "\tMAE 0.4861794 for 96 rounds, train-mae-mean: 0.3579384\n",
      "CV with max_depth=4, min_child_weight=2\n",
      "\tMAE 0.4865176 for 97 rounds, train-mae-mean: 0.35888480000000006\n",
      "CV with max_depth=4, min_child_weight=3\n",
      "\tMAE 0.4887662 for 35 rounds, train-mae-mean: 0.43413379999999996\n",
      "CV with max_depth=5, min_child_weight=1\n",
      "\tMAE 0.483174 for 121 rounds, train-mae-mean: 0.25035180000000007\n",
      "CV with max_depth=5, min_child_weight=2\n",
      "\tMAE 0.48436979999999996 for 96 rounds, train-mae-mean: 0.28997\n",
      "CV with max_depth=5, min_child_weight=3\n",
      "\tMAE 0.4852314 for 90 rounds, train-mae-mean: 0.30169159999999995\n",
      "CV with max_depth=6, min_child_weight=1\n",
      "\tMAE 0.4776454 for 202 rounds, train-mae-mean: 0.0984412\n",
      "CV with max_depth=6, min_child_weight=2\n",
      "\tMAE 0.4853044000000001 for 74 rounds, train-mae-mean: 0.25713400000000003\n",
      "CV with max_depth=6, min_child_weight=3\n",
      "\tMAE 0.4809794 for 126 rounds, train-mae-mean: 0.18964540000000002\n"
     ]
    }
   ],
   "source": [
    "#tune max_depth and min_child_weight (complexity of decision trees)\n",
    "gridsearch_params = [\n",
    "    (max_depth, min_child_weight)\n",
    "    for max_depth in range(3,7)\n",
    "    for min_child_weight in range(1,4)\n",
    "]\n",
    "\n",
    "# Define initial best params and MAE\n",
    "min_mae = float(\"Inf\")\n",
    "best_params = None\n",
    "for max_depth, min_child_weight in gridsearch_params:\n",
    "    print(\"CV with max_depth={}, min_child_weight={}\".format(\n",
    "                             max_depth,\n",
    "                             min_child_weight))\n",
    "    # Update our parameters\n",
    "    params['max_depth'] = max_depth\n",
    "    params['min_child_weight'] = min_child_weight\n",
    "    \n",
    "    # Run CV\n",
    "    cv_results = xgb.cv(\n",
    "        params,\n",
    "        dtrain,\n",
    "        num_boost_round=500,\n",
    "        seed=123,\n",
    "        nfold=5,\n",
    "        metrics={'mae'},\n",
    "        early_stopping_rounds=10\n",
    "    )\n",
    "    \n",
    "    # Update best MAE\n",
    "    mean_mae = cv_results['test-mae-mean'].min()\n",
    "    train_mean_mae = cv_results['train-mae-mean'].min()\n",
    "    boost_rounds = cv_results['test-mae-mean'].argmin()\n",
    "    print(\"\\tMAE {} for {} rounds, train-mae-mean: {}\".format(mean_mae, boost_rounds, train_mean_mae))\n",
    "    if mean_mae < min_mae:\n",
    "        min_mae = mean_mae\n",
    "        best_params = (max_depth,min_child_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV with max_depth=6, min_child_weight=1\n",
      "\tMAE 0.4776454 for 202 rounds, train-mae-mean: 0.0984412\n",
      "CV with max_depth=7, min_child_weight=1\n",
      "\tMAE 0.4729013999999999 for 228 rounds, train-mae-mean: 0.048008999999999996\n",
      "CV with max_depth=8, min_child_weight=1\n",
      "\tMAE 0.47547700000000004 for 125 rounds, train-mae-mean: 0.0722512\n"
     ]
    }
   ],
   "source": [
    "gridsearch_params = [\n",
    "    (max_depth, min_child_weight)\n",
    "    for max_depth in range(6,9)\n",
    "    for min_child_weight in range(1,2)\n",
    "]\n",
    "\n",
    "min_mae = float(\"Inf\")\n",
    "best_params = None\n",
    "for max_depth, min_child_weight in gridsearch_params:\n",
    "    print(\"CV with max_depth={}, min_child_weight={}\".format(\n",
    "                             max_depth,\n",
    "                             min_child_weight))\n",
    "    # Update our parameters\n",
    "    params['max_depth'] = max_depth\n",
    "    params['min_child_weight'] = min_child_weight\n",
    "    \n",
    "    # Run CV\n",
    "    cv_results = xgb.cv(\n",
    "        params,\n",
    "        dtrain,\n",
    "        num_boost_round=500,\n",
    "        seed=123,\n",
    "        nfold=5,\n",
    "        metrics={'mae'},\n",
    "        early_stopping_rounds=10\n",
    "    )\n",
    "    \n",
    "    # Update best MAE\n",
    "    mean_mae = cv_results['test-mae-mean'].min()\n",
    "    train_mean_mae = cv_results['train-mae-mean'].min()\n",
    "    boost_rounds = cv_results['test-mae-mean'].argmin()\n",
    "    print(\"\\tMAE {} for {} rounds, train-mae-mean: {}\".format(mean_mae, boost_rounds, train_mean_mae))\n",
    "    if mean_mae < min_mae:\n",
    "        min_mae = mean_mae\n",
    "        best_params = (max_depth,min_child_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "params['max_depth'] = 7\n",
    "params['min_child_weight'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tune Sampling HP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV with subsample=1.0, colsample=1.0\n",
      "\tMAE 0.4828682000000001 for 53 rounds, train-mae-mean: 0.22922159999999997\n",
      "CV with subsample=1.0, colsample=0.9\n",
      "\tMAE 0.47716519999999996 for 140 rounds, train-mae-mean: 0.08717280000000001\n",
      "CV with subsample=1.0, colsample=0.8\n",
      "\tMAE 0.4761062000000001 for 179 rounds, train-mae-mean: 0.06419640000000001\n",
      "CV with subsample=1.0, colsample=0.7\n",
      "\tMAE 0.4726952 for 274 rounds, train-mae-mean: 0.0340418\n",
      "CV with subsample=0.9, colsample=1.0\n",
      "\tMAE 0.47277199999999997 for 240 rounds, train-mae-mean: 0.041466\n",
      "CV with subsample=0.9, colsample=0.9\n",
      "\tMAE 0.47295040000000005 for 248 rounds, train-mae-mean: 0.039327999999999995\n",
      "CV with subsample=0.9, colsample=0.8\n",
      "\tMAE 0.47799040000000004 for 118 rounds, train-mae-mean: 0.11555439999999999\n",
      "CV with subsample=0.9, colsample=0.7\n",
      "\tMAE 0.4824878 for 66 rounds, train-mae-mean: 0.20530279999999998\n",
      "CV with subsample=0.8, colsample=1.0\n",
      "\tMAE 0.4729013999999999 for 228 rounds, train-mae-mean: 0.048008999999999996\n",
      "CV with subsample=0.8, colsample=0.9\n",
      "\tMAE 0.47942640000000003 for 98 rounds, train-mae-mean: 0.14649039999999997\n",
      "CV with subsample=0.8, colsample=0.8\n",
      "\tMAE 0.47478119999999996 for 131 rounds, train-mae-mean: 0.1056556\n",
      "CV with subsample=0.8, colsample=0.7\n",
      "\tMAE 0.47777539999999996 for 174 rounds, train-mae-mean: 0.076354\n",
      "CV with subsample=0.7, colsample=1.0\n",
      "\tMAE 0.477878 for 132 rounds, train-mae-mean: 0.1073318\n",
      "CV with subsample=0.7, colsample=0.9\n",
      "\tMAE 0.476452 for 165 rounds, train-mae-mean: 0.08298180000000001\n",
      "CV with subsample=0.7, colsample=0.8\n",
      "\tMAE 0.47341 for 167 rounds, train-mae-mean: 0.08322559999999998\n",
      "CV with subsample=0.7, colsample=0.7\n",
      "\tMAE 0.480587 for 133 rounds, train-mae-mean: 0.1123648\n"
     ]
    }
   ],
   "source": [
    "#tune sampling h-p\n",
    "gridsearch_params = [\n",
    "    (subsample, colsample)\n",
    "    for subsample in [i/10. for i in range(7,11)]\n",
    "    for colsample in [i/10. for i in range(7,11)]\n",
    "]\n",
    "\n",
    "min_mae = float(\"Inf\")\n",
    "best_params = None\n",
    "# We start by the largest values and go down to the smallest\n",
    "for subsample, colsample in reversed(gridsearch_params):\n",
    "    print(\"CV with subsample={}, colsample={}\".format(\n",
    "                             subsample,\n",
    "                             colsample))\n",
    "    # We update our parameters\n",
    "    params['subsample'] = subsample\n",
    "    params['colsample_bytree'] = colsample\n",
    "    # Run CV\n",
    "    cv_results = xgb.cv(\n",
    "        params,\n",
    "        dtrain,\n",
    "        num_boost_round=500,\n",
    "        seed=123,\n",
    "        nfold=5,\n",
    "        metrics={'mae'},\n",
    "        early_stopping_rounds=10\n",
    "    )\n",
    "    # Update best score\n",
    "    mean_mae = cv_results['test-mae-mean'].min()\n",
    "    train_mean_mae = cv_results['train-mae-mean'].min()\n",
    "    boost_rounds = cv_results['test-mae-mean'].argmin()\n",
    "    print(\"\\tMAE {} for {} rounds, train-mae-mean: {}\".format(mean_mae, boost_rounds, train_mean_mae))\n",
    "    if mean_mae < min_mae:\n",
    "        min_mae = mean_mae\n",
    "        best_params = (subsample,colsample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "params['subsample'] = 1.0\n",
    "params['colsample_bytree'] = 0.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Rate (ETA) tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV with eta=0.3\n",
      "\tMAE 0.46930459999999996 for 104 rounds, train-mae-mean: 0.0250508\n",
      "CV with eta=0.2\n",
      "\tMAE 0.476023 for 132 rounds, train-mae-mean: 0.0338902\n",
      "CV with eta=0.1\n",
      "\tMAE 0.4726952 for 274 rounds, train-mae-mean: 0.0340418\n",
      "CV with eta=0.05\n",
      "\tMAE 0.47683559999999997 for 281 rounds, train-mae-mean: 0.0968018\n",
      "CV with eta=0.01\n",
      "\tMAE 0.4839716 for 481 rounds, train-mae-mean: 0.25610180000000005\n",
      "CV with eta=0.005\n",
      "\tMAE 0.48716780000000004 for 499 rounds, train-mae-mean: 0.3469322\n"
     ]
    }
   ],
   "source": [
    "for eta in [.3, .2, .1, .05, .01, .005]:\n",
    "    print(\"CV with eta={}\".format(eta))\n",
    "    # We update our parameters\n",
    "    params['eta'] = eta\n",
    "    # Run CV\n",
    "    cv_results = xgb.cv(\n",
    "        params,\n",
    "        dtrain,\n",
    "        num_boost_round=500,\n",
    "        seed=123,\n",
    "        nfold=5,\n",
    "        metrics={'mae'},\n",
    "        early_stopping_rounds=10\n",
    "    )\n",
    "    # Update best score\n",
    "    mean_mae = cv_results['test-mae-mean'].min()\n",
    "    train_mean_mae = cv_results['train-mae-mean'].min()\n",
    "    boost_rounds = cv_results['test-mae-mean'].argmin()\n",
    "    print(\"\\tMAE {} for {} rounds, train-mae-mean: {}\".format(mean_mae, boost_rounds, train_mean_mae))\n",
    "    if mean_mae < min_mae:\n",
    "        min_mae = mean_mae\n",
    "        best_params = (subsample,colsample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "params['eta'] = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.7, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=7,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=200, n_jobs=0, num_parallel_tree=1,\n",
       "              objective='binary:logistic', random_state=0, reg_alpha=0,\n",
       "              reg_lambda=1, scale_pos_weight=1, subsample=1.0,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = xgb.XGBClassifier(max_depth=7, learning_rate=0.1, objective='binary:logistic', \\\n",
    "                      min_child_weight=1, subsample=1.0, colsample_bytree=0.7, n_estimators=200)\n",
    "\n",
    "clf.fit(X_train, y_train, eval_metric=f1_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, ..., 1, 1, 0])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = clf.predict(test_doc2vec_features)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_preds = pd.Series(preds)\n",
    "test_ids = df_test['id']\n",
    "df_preds = pd.concat([test_ids,final_preds],axis=1)\n",
    "df_preds.columns = ['id', 'target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3258</th>\n",
       "      <td>10861</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3259</th>\n",
       "      <td>10865</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3260</th>\n",
       "      <td>10868</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3261</th>\n",
       "      <td>10874</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3262</th>\n",
       "      <td>10875</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  target\n",
       "3258  10861       0\n",
       "3259  10865       0\n",
       "3260  10868       1\n",
       "3261  10874       1\n",
       "3262  10875       0"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_preds.to_csv('XGBoost_submission.csv')\n",
    "df_preds.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
