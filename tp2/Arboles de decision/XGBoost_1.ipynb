{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gensim to pre process text\n",
    "from gensim import utils\n",
    "import gensim.parsing.preprocessing as gsp\n",
    "\n",
    "filters = [ \n",
    "           gsp.strip_punctuation,\n",
    "           gsp.strip_multiple_whitespaces,\n",
    "           gsp.strip_numeric,\n",
    "           gsp.remove_stopwords, \n",
    "           gsp.strip_short, \n",
    "           gsp.stem_text\n",
    "          ]\n",
    "\n",
    "def clean_text(s):\n",
    "    s = s.lower()\n",
    "    s = utils.to_unicode(s)\n",
    "    for f in filters:\n",
    "        s = f(s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import TaggedDocument, Doc2Vec\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn import utils as skl_utils\n",
    "from tqdm import tqdm\n",
    "\n",
    "import multiprocessing\n",
    "import numpy as np\n",
    "\n",
    "class Doc2VecTransformer(BaseEstimator):\n",
    "\n",
    "    def __init__(self, vector_size=300, learning_rate=0.02, epochs=20):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epochs = epochs\n",
    "        self._model = None\n",
    "        self.vector_size = vector_size\n",
    "        self.workers = multiprocessing.cpu_count() - 1\n",
    "\n",
    "    def fit(self, df_x, df_y=None):\n",
    "        tagged_x = [TaggedDocument(clean_text(row).split(), [index]) for index, row in enumerate(df_x)]\n",
    "        model = Doc2Vec(documents=tagged_x, vector_size=self.vector_size, workers=self.workers)\n",
    "\n",
    "        for epoch in range(self.epochs):\n",
    "            model.train(skl_utils.shuffle([x for x in tqdm(tagged_x)]), total_examples=len(tagged_x), epochs=1)\n",
    "            model.alpha -= self.learning_rate\n",
    "            model.min_alpha = model.alpha\n",
    "\n",
    "        self._model = model\n",
    "        return self\n",
    "\n",
    "    def transform(self, df_x):\n",
    "        return np.asmatrix(np.array([self._model.infer_vector(clean_text(row).split())\n",
    "                                     for index, row in enumerate(df_x)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "\n",
    "def f1_eval(y_pred, dtrain):\n",
    "    y_true = dtrain.get_label()\n",
    "    f1_score = f1_score(y_true, np.round(y_pred))\n",
    "    return 'f1_score', f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv')\n",
    "df_test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['keyword', 'location'], axis=1, inplace=True)\n",
    "df_test.drop(['keyword', 'location'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x = df['text']\n",
    "df_y = df['target']\n",
    "\n",
    "df_test_x = df_test['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7613/7613 [00:00<00:00, 4091649.97it/s]\n",
      "100%|██████████| 7613/7613 [00:00<00:00, 4286647.38it/s]\n",
      "100%|██████████| 7613/7613 [00:00<00:00, 3922756.31it/s]\n",
      "100%|██████████| 7613/7613 [00:00<00:00, 4480319.40it/s]\n",
      "100%|██████████| 7613/7613 [00:00<00:00, 4627715.41it/s]\n",
      "100%|██████████| 7613/7613 [00:00<00:00, 4690252.11it/s]\n",
      "100%|██████████| 7613/7613 [00:00<00:00, 3973029.28it/s]\n",
      "100%|██████████| 7613/7613 [00:00<00:00, 4258065.92it/s]\n",
      "100%|██████████| 7613/7613 [00:00<00:00, 4326139.60it/s]\n",
      "100%|██████████| 7613/7613 [00:00<00:00, 4439209.84it/s]\n",
      "100%|██████████| 7613/7613 [00:00<00:00, 3862026.65it/s]\n",
      "100%|██████████| 7613/7613 [00:00<00:00, 4197060.51it/s]\n",
      "100%|██████████| 7613/7613 [00:00<00:00, 4347343.27it/s]\n",
      "100%|██████████| 7613/7613 [00:00<00:00, 4119627.96it/s]\n",
      "100%|██████████| 7613/7613 [00:00<00:00, 4477178.40it/s]\n",
      "100%|██████████| 7613/7613 [00:00<00:00, 4527326.86it/s]\n",
      "100%|██████████| 7613/7613 [00:00<00:00, 4541492.87it/s]\n",
      "100%|██████████| 7613/7613 [00:00<00:00, 4681313.06it/s]\n",
      "100%|██████████| 7613/7613 [00:00<00:00, 4295874.66it/s]\n",
      "100%|██████████| 7613/7613 [00:00<00:00, 4651309.01it/s]\n",
      "100%|██████████| 3263/3263 [00:00<00:00, 3616811.30it/s]\n",
      "100%|██████████| 3263/3263 [00:00<00:00, 4161147.45it/s]\n",
      "100%|██████████| 3263/3263 [00:00<00:00, 3745488.22it/s]\n",
      "100%|██████████| 3263/3263 [00:00<00:00, 3731192.46it/s]\n",
      "100%|██████████| 3263/3263 [00:00<00:00, 4274207.98it/s]\n",
      "100%|██████████| 3263/3263 [00:00<00:00, 3914763.72it/s]\n",
      "100%|██████████| 3263/3263 [00:00<00:00, 4139750.14it/s]\n",
      "100%|██████████| 3263/3263 [00:00<00:00, 3656429.05it/s]\n",
      "100%|██████████| 3263/3263 [00:00<00:00, 3111872.20it/s]\n",
      "100%|██████████| 3263/3263 [00:00<00:00, 3723072.35it/s]\n",
      "100%|██████████| 3263/3263 [00:00<00:00, 3650577.21it/s]\n",
      "100%|██████████| 3263/3263 [00:00<00:00, 4251635.28it/s]\n",
      "100%|██████████| 3263/3263 [00:00<00:00, 3883658.90it/s]\n",
      "100%|██████████| 3263/3263 [00:00<00:00, 4097608.97it/s]\n",
      "100%|██████████| 3263/3263 [00:00<00:00, 3414674.14it/s]\n",
      "100%|██████████| 3263/3263 [00:00<00:00, 3361005.39it/s]\n",
      "100%|██████████| 3263/3263 [00:00<00:00, 3794292.75it/s]\n",
      "100%|██████████| 3263/3263 [00:00<00:00, 3333986.35it/s]\n",
      "100%|██████████| 3263/3263 [00:00<00:00, 1640812.13it/s]\n",
      "100%|██████████| 3263/3263 [00:00<00:00, 3706937.69it/s]\n"
     ]
    }
   ],
   "source": [
    "doc2vec_trf = Doc2VecTransformer()\n",
    "\n",
    "doc2vec_features = doc2vec_trf.fit(df_x).transform(df_x)\n",
    "\n",
    "test_doc2vec_features = doc2vec_trf.fit(df_test_x).transform(df_test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HP Tuning with Grid-Search and K-fold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'max_depth':10,\n",
    "    'min_child_weight': 3,\n",
    "    'eta':.05,\n",
    "    'subsample': 1,\n",
    "    'colsample_bytree': 0.3,\n",
    "    'objective':'binary:logistic',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "train_dmatrix = xgb.DMatrix(data=tfidf_vectors,label=df_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tune Complexity of decision trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV with max_depth=3, min_child_weight=1\n",
      "\tMAE 0.371357 for 499 rounds, train-mae-mean: 0.3482546\n",
      "CV with max_depth=3, min_child_weight=2\n",
      "\tMAE 0.37191300000000005 for 499 rounds, train-mae-mean: 0.34972060000000005\n",
      "CV with max_depth=3, min_child_weight=3\n",
      "\tMAE 0.3716826 for 499 rounds, train-mae-mean: 0.35012999999999994\n",
      "CV with max_depth=4, min_child_weight=1\n",
      "\tMAE 0.36179439999999996 for 499 rounds, train-mae-mean: 0.3300994\n",
      "CV with max_depth=4, min_child_weight=2\n",
      "\tMAE 0.3622718 for 499 rounds, train-mae-mean: 0.332359\n",
      "CV with max_depth=4, min_child_weight=3\n",
      "\tMAE 0.362144 for 499 rounds, train-mae-mean: 0.333619\n",
      "CV with max_depth=5, min_child_weight=1\n",
      "\tMAE 0.3548028 for 499 rounds, train-mae-mean: 0.3147006\n",
      "CV with max_depth=5, min_child_weight=2\n",
      "\tMAE 0.3553468 for 499 rounds, train-mae-mean: 0.31791800000000003\n",
      "CV with max_depth=5, min_child_weight=3\n",
      "\tMAE 0.3555212 for 499 rounds, train-mae-mean: 0.3199236\n",
      "CV with max_depth=6, min_child_weight=1\n",
      "\tMAE 0.3485202 for 499 rounds, train-mae-mean: 0.3010372\n",
      "CV with max_depth=6, min_child_weight=2\n",
      "\tMAE 0.3492844 for 499 rounds, train-mae-mean: 0.3047514\n",
      "CV with max_depth=6, min_child_weight=3\n",
      "\tMAE 0.35028820000000005 for 499 rounds, train-mae-mean: 0.307856\n"
     ]
    }
   ],
   "source": [
    "#tune max_depth and min_child_weight (complexity of decision trees)\n",
    "gridsearch_params = [\n",
    "    (max_depth, min_child_weight)\n",
    "    for max_depth in range(3,7)\n",
    "    for min_child_weight in range(1,4)\n",
    "]\n",
    "\n",
    "# Define initial best params and MAE\n",
    "min_mae = float(\"Inf\")\n",
    "best_params = None\n",
    "for max_depth, min_child_weight in gridsearch_params:\n",
    "    print(\"CV with max_depth={}, min_child_weight={}\".format(\n",
    "                             max_depth,\n",
    "                             min_child_weight))\n",
    "    # Update our parameters\n",
    "    params['max_depth'] = max_depth\n",
    "    params['min_child_weight'] = min_child_weight\n",
    "    \n",
    "    # Run CV\n",
    "    cv_results = xgb.cv(\n",
    "        params,\n",
    "        train_dmatrix,\n",
    "        num_boost_round=500,\n",
    "        seed=123,\n",
    "        nfold=5,\n",
    "        metrics={'mae'},\n",
    "        early_stopping_rounds=10\n",
    "    )\n",
    "    \n",
    "    # Update best MAE\n",
    "    mean_mae = cv_results['test-mae-mean'].min()\n",
    "    train_mean_mae = cv_results['train-mae-mean'].min()\n",
    "    boost_rounds = cv_results['test-mae-mean'].argmin()\n",
    "    print(\"\\tMAE {} for {} rounds, train-mae-mean: {}\".format(mean_mae, boost_rounds, train_mean_mae))\n",
    "    if mean_mae < min_mae:\n",
    "        min_mae = mean_mae\n",
    "        best_params = (max_depth,min_child_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV with max_depth=6, min_child_weight=1\n",
      "\tMAE 0.3485202 for 499 rounds, train-mae-mean: 0.3010372\n",
      "CV with max_depth=7, min_child_weight=1\n",
      "\tMAE 0.34390620000000005 for 499 rounds, train-mae-mean: 0.2886808\n",
      "CV with max_depth=8, min_child_weight=1\n",
      "\tMAE 0.34000899999999995 for 499 rounds, train-mae-mean: 0.2777596\n"
     ]
    }
   ],
   "source": [
    "gridsearch_params = [\n",
    "    (max_depth, min_child_weight)\n",
    "    for max_depth in range(6,9)\n",
    "    for min_child_weight in range(1,2)\n",
    "]\n",
    "\n",
    "min_mae = float(\"Inf\")\n",
    "best_params = None\n",
    "for max_depth, min_child_weight in gridsearch_params:\n",
    "    print(\"CV with max_depth={}, min_child_weight={}\".format(\n",
    "                             max_depth,\n",
    "                             min_child_weight))\n",
    "    # Update our parameters\n",
    "    params['max_depth'] = max_depth\n",
    "    params['min_child_weight'] = min_child_weight\n",
    "    \n",
    "    # Run CV\n",
    "    cv_results = xgb.cv(\n",
    "        params,\n",
    "        train_dmatrix,\n",
    "        num_boost_round=500,\n",
    "        seed=123,\n",
    "        nfold=5,\n",
    "        metrics={'mae'},\n",
    "        early_stopping_rounds=10\n",
    "    )\n",
    "    \n",
    "    # Update best MAE\n",
    "    mean_mae = cv_results['test-mae-mean'].min()\n",
    "    train_mean_mae = cv_results['train-mae-mean'].min()\n",
    "    boost_rounds = cv_results['test-mae-mean'].argmin()\n",
    "    print(\"\\tMAE {} for {} rounds, train-mae-mean: {}\".format(mean_mae, boost_rounds, train_mean_mae))\n",
    "    if mean_mae < min_mae:\n",
    "        min_mae = mean_mae\n",
    "        best_params = (max_depth,min_child_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "params['max_depth'] = 6\n",
    "params['min_child_weight'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tune Sampling HP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV with subsample=1.0, colsample=1.0\n",
      "\tMAE 0.3463596 for 499 rounds, train-mae-mean: 0.2942164\n",
      "CV with subsample=1.0, colsample=0.9\n",
      "\tMAE 0.34655620000000004 for 499 rounds, train-mae-mean: 0.2947392\n",
      "CV with subsample=1.0, colsample=0.8\n",
      "\tMAE 0.3469364 for 499 rounds, train-mae-mean: 0.29530019999999996\n",
      "CV with subsample=1.0, colsample=0.7\n",
      "\tMAE 0.34708560000000005 for 499 rounds, train-mae-mean: 0.296269\n",
      "CV with subsample=0.9, colsample=1.0\n",
      "\tMAE 0.34313580000000005 for 499 rounds, train-mae-mean: 0.2871434\n",
      "CV with subsample=0.9, colsample=0.9\n",
      "\tMAE 0.3432288 for 499 rounds, train-mae-mean: 0.28838220000000003\n",
      "CV with subsample=0.9, colsample=0.8\n",
      "\tMAE 0.34339339999999996 for 499 rounds, train-mae-mean: 0.2893772\n",
      "CV with subsample=0.9, colsample=0.7\n",
      "\tMAE 0.3438074 for 499 rounds, train-mae-mean: 0.2900218\n",
      "CV with subsample=0.8, colsample=1.0\n",
      "\tMAE 0.3419082 for 499 rounds, train-mae-mean: 0.286242\n",
      "CV with subsample=0.8, colsample=0.9\n",
      "\tMAE 0.34229980000000004 for 499 rounds, train-mae-mean: 0.286993\n",
      "CV with subsample=0.8, colsample=0.8\n",
      "\tMAE 0.34255979999999997 for 499 rounds, train-mae-mean: 0.28805699999999995\n",
      "CV with subsample=0.8, colsample=0.7\n",
      "\tMAE 0.34284299999999995 for 499 rounds, train-mae-mean: 0.2891338\n",
      "CV with subsample=0.7, colsample=1.0\n",
      "\tMAE 0.3422646 for 499 rounds, train-mae-mean: 0.2859868\n",
      "CV with subsample=0.7, colsample=0.9\n",
      "\tMAE 0.34269099999999997 for 499 rounds, train-mae-mean: 0.28644260000000005\n",
      "CV with subsample=0.7, colsample=0.8\n",
      "\tMAE 0.34266880000000005 for 499 rounds, train-mae-mean: 0.2875628\n",
      "CV with subsample=0.7, colsample=0.7\n",
      "\tMAE 0.343269 for 499 rounds, train-mae-mean: 0.2887622\n"
     ]
    }
   ],
   "source": [
    "#tune sampling h-p\n",
    "gridsearch_params = [\n",
    "    (subsample, colsample)\n",
    "    for subsample in [i/10. for i in range(7,11)]\n",
    "    for colsample in [i/10. for i in range(7,11)]\n",
    "]\n",
    "\n",
    "min_mae = float(\"Inf\")\n",
    "best_params = None\n",
    "# We start by the largest values and go down to the smallest\n",
    "for subsample, colsample in reversed(gridsearch_params):\n",
    "    print(\"CV with subsample={}, colsample={}\".format(\n",
    "                             subsample,\n",
    "                             colsample))\n",
    "    # We update our parameters\n",
    "    params['subsample'] = subsample\n",
    "    params['colsample_bytree'] = colsample\n",
    "    # Run CV\n",
    "    cv_results = xgb.cv(\n",
    "        params,\n",
    "        train_dmatrix,\n",
    "        num_boost_round=500,\n",
    "        seed=123,\n",
    "        nfold=5,\n",
    "        metrics={'mae'},\n",
    "        early_stopping_rounds=10\n",
    "    )\n",
    "    # Update best score\n",
    "    mean_mae = cv_results['test-mae-mean'].min()\n",
    "    train_mean_mae = cv_results['train-mae-mean'].min()\n",
    "    boost_rounds = cv_results['test-mae-mean'].argmin()\n",
    "    print(\"\\tMAE {} for {} rounds, train-mae-mean: {}\".format(mean_mae, boost_rounds, train_mean_mae))\n",
    "    if mean_mae < min_mae:\n",
    "        min_mae = mean_mae\n",
    "        best_params = (subsample,colsample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "params['subsample'] = 0.8\n",
    "params['colsample_bytree'] = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Rate (ETA) tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV with eta=0.3\n",
      "\tMAE 0.3062984 for 406 rounds, train-mae-mean: 0.15545340000000002\n",
      "CV with eta=0.2\n",
      "\tMAE 0.30976440000000005 for 499 rounds, train-mae-mean: 0.17517699999999997\n",
      "CV with eta=0.1\n",
      "\tMAE 0.3230392 for 499 rounds, train-mae-mean: 0.2361078\n",
      "CV with eta=0.05\n",
      "\tMAE 0.3419082 for 499 rounds, train-mae-mean: 0.286242\n",
      "CV with eta=0.01\n",
      "\tMAE 0.3910786 for 499 rounds, train-mae-mean: 0.3687856\n",
      "CV with eta=0.005\n",
      "\tMAE 0.4125166 for 499 rounds, train-mae-mean: 0.3969176\n"
     ]
    }
   ],
   "source": [
    "for eta in [.3, .2, .1, .05, .01, .005]:\n",
    "    print(\"CV with eta={}\".format(eta))\n",
    "    # We update our parameters\n",
    "    params['eta'] = eta\n",
    "    # Run CV\n",
    "    cv_results = xgb.cv(\n",
    "        params,\n",
    "        train_dmatrix,\n",
    "        num_boost_round=500,\n",
    "        seed=123,\n",
    "        nfold=5,\n",
    "        metrics={'mae'},\n",
    "        early_stopping_rounds=10\n",
    "    )\n",
    "    # Update best score\n",
    "    mean_mae = cv_results['test-mae-mean'].min()\n",
    "    train_mean_mae = cv_results['train-mae-mean'].min()\n",
    "    boost_rounds = cv_results['test-mae-mean'].argmin()\n",
    "    print(\"\\tMAE {} for {} rounds, train-mae-mean: {}\".format(mean_mae, boost_rounds, train_mean_mae))\n",
    "    if mean_mae < min_mae:\n",
    "        min_mae = mean_mae\n",
    "        best_params = (subsample,colsample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "params['eta'] = 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1.0, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.05, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=200, n_jobs=0, num_parallel_tree=1,\n",
       "              objective='binary:logistic', random_state=0, reg_alpha=0,\n",
       "              reg_lambda=1, scale_pos_weight=1, subsample=0.8,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = xgb.XGBClassifier(max_depth=6, learning_rate=0.05, objective='binary:logistic', \\\n",
    "                      min_child_weight=1, subsample=0.8, colsample_bytree=1.0, n_estimators=200)\n",
    "\n",
    "clf.fit(doc2vec_features, df_y, eval_metric=f1_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, ..., 1, 1, 0])"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = clf.predict(test_doc2vec_features)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_preds = pd.Series(preds)\n",
    "test_ids = df_test['id']\n",
    "df_preds = pd.concat([test_ids,final_preds],axis=1)\n",
    "df_preds.columns = ['id', 'target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3258</th>\n",
       "      <td>10861</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3259</th>\n",
       "      <td>10865</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3260</th>\n",
       "      <td>10868</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3261</th>\n",
       "      <td>10874</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3262</th>\n",
       "      <td>10875</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  target\n",
       "3258  10861       0\n",
       "3259  10865       1\n",
       "3260  10868       1\n",
       "3261  10874       1\n",
       "3262  10875       0"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_preds.to_csv('XGBoost_submission.csv')\n",
    "df_preds.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
