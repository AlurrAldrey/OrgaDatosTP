{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import hstack\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('final_train.csv')\n",
    "\n",
    "#Completo los NaN que se generan al importar del CSV\n",
    "train.update(train[['hashtags', 'mentions', 'urls', 'clean_text', 'punctuation_signs', 'lemma_text', 'porter_stemmed_text', 'snowball_stemmed_text']].fillna(\"\"))\n",
    "\n",
    "test = train.loc[train['source'] == 'test']\n",
    "train = train.loc[train['source'] == 'train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 7503 entries, 0 to 7502\n",
      "Data columns (total 35 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   id                        7503 non-null   int64  \n",
      " 1   keyword                   7503 non-null   object \n",
      " 2   location                  5028 non-null   object \n",
      " 3   text                      7503 non-null   object \n",
      " 4   target                    7503 non-null   float64\n",
      " 5   country                   7503 non-null   object \n",
      " 6   city                      7503 non-null   object \n",
      " 7   lat                       4273 non-null   float64\n",
      " 8   lon                       4273 non-null   float64\n",
      " 9   source                    7503 non-null   object \n",
      " 10  words                     7503 non-null   object \n",
      " 11  real_words                7503 non-null   object \n",
      " 12  clean_text                7503 non-null   object \n",
      " 13  punctuation_signs         7503 non-null   object \n",
      " 14  hashtags                  7503 non-null   object \n",
      " 15  mentions                  7503 non-null   object \n",
      " 16  urls                      7503 non-null   object \n",
      " 17  entities_count            7503 non-null   int64  \n",
      " 18  words_count               7503 non-null   int64  \n",
      " 19  punctuations_signs_count  7503 non-null   int64  \n",
      " 20  hashtags_count            7503 non-null   int64  \n",
      " 21  mentions_count            7503 non-null   int64  \n",
      " 22  urls_count                7503 non-null   int64  \n",
      " 23  stopwords_count           7503 non-null   int64  \n",
      " 24  words_length_avg          7503 non-null   float64\n",
      " 25  punctuations_ratio        7503 non-null   float64\n",
      " 26  hashtags_ratio            7503 non-null   float64\n",
      " 27  mentions_ratio            7503 non-null   float64\n",
      " 28  urls_ratio                7503 non-null   float64\n",
      " 29  stopwords_ratio           7503 non-null   float64\n",
      " 30  special_entities_ratio    7503 non-null   float64\n",
      " 31  keyword_cv_mean_enc       7503 non-null   float64\n",
      " 32  lemma_text                7503 non-null   object \n",
      " 33  porter_stemmed_text       7503 non-null   object \n",
      " 34  snowball_stemmed_text     7503 non-null   object \n",
      "dtypes: float64(11), int64(8), object(16)\n",
      "memory usage: 2.1+ MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateSubmission(predicts, model):\n",
    "    submission = test[['id', 'target']]\n",
    "    submission['target'] = predicts\n",
    "    submission['target'] = submission['target'].astype(int)\n",
    "    submission.to_csv(model + '_pred.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_numeric = train[['entities_count', 'words_count', 'punctuations_signs_count', 'hashtags_count', 'mentions_count', 'urls_count', \n",
    "           'stopwords_count', 'words_length_avg', 'punctuations_ratio', 'mentions_ratio', 'urls_ratio', 'stopwords_ratio',\n",
    "           'special_entities_ratio', 'keyword_cv_mean_enc']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfIdfVectorization(df, columnName, ngram_range=(1, 1), min_df=1):\n",
    "    return TfidfVectorizer(sublinear_tf=True, ngram_range=ngram_range, min_df=min_df, norm='l2').fit(np.array(train['text']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bowVectorization(df, columnName, min_df=5):\n",
    "    return CountVectorizer(min_df=min_df).fit(np.array(df[columnName]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformVector(vector, df, columnName):\n",
    "    return vector.transform(np.array(df[columnName]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prueba TFIDF todo junto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "def executeTest(name='test', testing=True, model='nb'):\n",
    "    text_vector = tfIdfVectorization(train, 'text', min_df=5)\n",
    "    hashtags_vector = bowVectorization(train, 'hashtags', min_df=1)\n",
    "    mentions_vector = bowVectorization(train, 'mentions', min_df=5)\n",
    "    realwords_vector = tfIdfVectorization(train, 'real_words', min_df=5)\n",
    "    \n",
    "    transformed_text_vector = transformVector(text_vector, train, 'text')\n",
    "    transformed_hashtags_vector = transformVector(hashtags_vector, train, 'hashtags')\n",
    "    transformed_mentions_vector = transformVector(mentions_vector, train, 'mentions')\n",
    "    transformed_realwords_vector = transformVector(realwords_vector, train, 'real_words')\n",
    "    XT = hstack((transformed_text_vector, transformed_hashtags_vector, transformed_mentions_vector, transformed_realwords_vector))\n",
    "    y = np.array(train['target'])\n",
    "    X_train, X_test, y_train, y_test = train_test_split(XT, y, test_size=0.2, random_state=30)\n",
    "    \n",
    "    if model == 'nb':\n",
    "        nb_model = MultinomialNB()\n",
    "        if testing:\n",
    "            nb_model.fit(X_train, y_train)\n",
    "            predicts = nb_model.predict(X_test)\n",
    "            print(\"Score NB:\", f1_score(y_test, predicts))\n",
    "        else:\n",
    "            nb_model.fit(XT, y)\n",
    "            predicts = nb_model.predict(X_test)\n",
    "            text_vector_test = transformVector(text_vector, test, 'text')\n",
    "            hashtags_vector_test = transformVector(hashtags_vector, test, 'hashtags')\n",
    "            mentions_vector_test = transformVector(mentions_vector, test, 'mentions')\n",
    "            realwords_vector_test = transformVector(realwords_vector, test, 'real_words')\n",
    "            XT_r = hstack((text_vector_test, hashtags_vector_test, mentions_vector_test, realwords_vector_test))\n",
    "            subm = nb_model.predict(XT_r)\n",
    "            generateSubmission(subm, 'nb_' + name)\n",
    "    else :\n",
    "        lr_model = LogisticRegression(solver='liblinear')\n",
    "        if testing:\n",
    "            lr_model.fit(X_train, y_train)\n",
    "            predicts = lr_model.predict(X_test)\n",
    "            print(\"Score LR:\", f1_score(y_test, predicts))\n",
    "        else:\n",
    "            lr_model.fit(XT, y)\n",
    "            predicts = lr_model.predict(X_test)\n",
    "            text_vector_test = transformVector(text_vector, test, 'text')\n",
    "            hashtags_vector_test = transformVector(hashtags_vector, test, 'hashtags')\n",
    "            mentions_vector_test = transformVector(mentions_vector, test, 'mentions')\n",
    "            realwords_vector_test = transformVector(realwords_vector, test, 'real_words')\n",
    "            XT_r = hstack((text_vector_test, hashtags_vector_test, mentions_vector_test, realwords_vector_test))\n",
    "            subm = lr_model.predict(XT_r)\n",
    "            generateSubmission(subm, 'lr_' + name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Miniconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\ProgramData\\Miniconda3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "executeTest(model='lr', testing=False, name='real_words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_vector = tfIdfVectorization(train, 'text', min_df=5)\n",
    "hashtags_vector = bowVectorization(train, 'hashtags', min_df=1)\n",
    "mentions_vector = bowVectorization(train, 'mentions', min_df=5)\n",
    "realwords_vector = tfIdfVectorization(train, 'real_words', min_df=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_text_vector = transformVector(text_vector, train, 'text')\n",
    "transformed_hashtags_vector = transformVector(hashtags_vector, train, 'hashtags')\n",
    "transformed_mentions_vector = transformVector(mentions_vector, train, 'mentions')\n",
    "transformed_realwords_vector = transformVector(realwords_vector, train, 'real_words')\n",
    "XT = hstack((transformed_text_vector, transformed_hashtags_vector, transformed_mentions_vector, transformed_realwords_vector))\n",
    "y = np.array(train['target'])\n",
    "#X_train = XT\n",
    "#y_train = y\n",
    "X_train, X_test, y_train, y_test = train_test_split(XT, y, test_size=0.2, random_state=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score NB: 0.7627118644067795\n"
     ]
    }
   ],
   "source": [
    "## NaiveBayes\n",
    "nb_model = MultinomialNB()\n",
    "#nb_model.fit(XT, y)\n",
    "nb_model.fit(X_train, y_train)\n",
    "predicts = nb_model.predict(X_test)\n",
    "print(\"Score NB:\", f1_score(y_test, predicts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score LR: 0.7653490328006729\n"
     ]
    }
   ],
   "source": [
    "## Logistic Regression\n",
    "lr_model = LogisticRegression(solver='liblinear')\n",
    "lr_model.fit(X_train, y_train)\n",
    "predicts = lr_model.predict(X_test)\n",
    "print(\"Score LR:\", f1_score(y_test, predicts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_vector_test = transformVector(text_vector, test, 'text')\n",
    "hashtags_vector_test = transformVector(hashtags_vector, test, 'hashtags')\n",
    "mentions_vector_test = transformVector(mentions_vector, test, 'mentions')\n",
    "realwords_vector_test = transformVector(realwords_vector, test, 'real_words')\n",
    "XT_r = hstack((text_vector_test, hashtags_vector_test, mentions_vector_test, realwords_vector_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subm = nb_model.predict(XT_r)\n",
    "generateSubmission(subm, 'nb_tfidf_bow_tunned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "transform not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-101-f1baadfee136>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Predigo para lo real\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mx1_r\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtext_vector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'lemma_text'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mx2_r\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhashtags_vector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'hashtags'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mx3_r\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmentions_vector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'mentions'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mx4_r\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0murls_vector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'urls'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\scipy\\sparse\\base.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, attr)\u001b[0m\n\u001b[0;32m    689\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetnnz\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    690\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 691\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mattr\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\" not found\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    692\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    693\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: transform not found"
     ]
    }
   ],
   "source": [
    "#Predigo para lo real\n",
    "x1_r = text_vector.transform(np.array(test['clean_text']).ravel())\n",
    "x2_r = hashtags_vector.transform(np.array(test['hashtags']).ravel())\n",
    "x3_r = mentions_vector.transform(np.array(test['mentions']).ravel())\n",
    "x4_r = urls_vector.transform(np.array(test['real_words']).ravel())\n",
    "XT_r = hstack((x1_r, x2_r, x3_r, x4_r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subm = nb_model.predict(XT_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generateSubmission(subm, 'nb_full')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomForestGridSearch():\n",
    "    X_train, X_test, y_train, y_test = train_test_split(train_numeric.values, train['target'].values, test_size=0.2, random_state=530)\n",
    "    \n",
    "    rf_folds = 5\n",
    "    rf_grid = dict(n_estimators=[3, 6, 9, 12], max_depth=[4, 8, 12], min_samples_split=[15, 30, 45, 60], min_samples_leaf=[15, 30, 45, 60], max_features=[5, 10, 13])\n",
    "    clf = GridSearchCV(estimator=RandomForestClassifier(random_state=51), param_grid=rf_grid, n_jobs=-1, cv=rf_folds, scoring='f1', error_score=0)\n",
    "    clf.fit(X_train, y_train)\n",
    "    print(\"Mejores parametros encontrados:\", clf.best_params_)\n",
    "\n",
    "    rf_best_model = RandomForestClassifier(random_state=51, n_estimators=clf.best_params_['n_estimators'], max_features=clf.best_params_['max_features'], min_samples_leaf=clf.best_params_['min_samples_leaf'], min_samples_split=clf.best_params_['min_samples_split'], max_depth=clf.best_params_['max_depth'])\n",
    "    rf_best_model.fit(X_train, y_train)\n",
    "    preds = rf_best_model.predict(X_test)\n",
    "    print(\"Score RF:\", f1_score(y_test, preds))\n",
    "    \n",
    "    print(train_numeric.columns)\n",
    "    print(rfModel.feature_importances_)\n",
    "    \n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_numeric.columns)\n",
    "print(rfModel.feature_importances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naiveBayesGridSearch(columnName):\n",
    "    vector = tdfIdfVectorization(columnName)\n",
    "    \n",
    "    X = vector.transform(np.array(train[columnName]).ravel())\n",
    "    y = np.array(train['target']).ravel()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=30)\n",
    "    \n",
    "    nb_model = MultinomialNB()\n",
    "    nb_model.fit(X_train, y_train)\n",
    "    predicts = nb_model.predict(X_test)\n",
    "    print(\"Score NB:\", f1_score(y_test, predicts))\n",
    "    \n",
    "    return predicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "naiveBayesGridSearch('lemma_text')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#values para 1 columna: np.array(train[columnName]).ravel()\n",
    "def logisticRegressionGridSearch(values):\n",
    "    vector = TfidfVectorizer(sublinear_tf=True)\n",
    "    vector.fit(values)\n",
    "    \n",
    "    X = vector.transform(values)\n",
    "    y = np.array(train['target']).ravel()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=30)\n",
    "    \n",
    "    lr_folds = 10\n",
    "    lr_grid = dict(solver=['liblinear', 'lbfgs', 'saga'], penalty=['l1', 'l2', 'elasticnet'], C=[0.5, 0.75, 1.0, 1.25, 1.5])\n",
    "    clf = GridSearchCV(estimator=LogisticRegression(random_state=51), param_grid=lr_grid, n_jobs=-1, cv=lr_folds, scoring='f1', error_score=0)\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    print(\"Best params:\", clf.best_params_)\n",
    "    \n",
    "    predicts = clf.predict(X_test)\n",
    "    print(\"Score LR:\", f1_score(y_test, predicts))\n",
    "    \n",
    "    return predicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logisticRegressionFullGridSearch(XT):\n",
    "    y = np.array(train['target']).ravel()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(XT, y, test_size=0.2, random_state=30)\n",
    "    \n",
    "    lr_folds = 10\n",
    "    lr_grid = dict(solver=['liblinear', 'lbfgs', 'saga'], penalty=['l1', 'l2', 'elasticnet'], C=[1.5, 1.55, 1.65, 1.70])\n",
    "    clf = GridSearchCV(estimator=LogisticRegression(random_state=51), param_grid=lr_grid, n_jobs=-1, cv=lr_folds, scoring='f1', error_score=0)\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    predicts = clf.predict(X_test)\n",
    "    print(\"Score LR:\", f1_score(y_test, predicts))\n",
    "    \n",
    "    print(\"Best params:\", clf.best_params_)\n",
    "    \n",
    "    return predicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'C': 1.5, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "Score LR: 0.7397020157756354\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0., 1., 0., ..., 1., 1., 0.])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logisticRegressionGridSearch(np.array(train['lemma_text']).ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'C': 1.5, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "Score LR: 0.7445887445887446\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0., 1., 0., ..., 1., 1., 0.])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logisticRegressionGridSearch(np.array(train['porter_stemmed_text']).ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score LR: 0.7422145328719724\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0., 1., 0., ..., 1., 1., 0.])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logisticRegressionGridSearch(np.array(train['snowball_stemmed_text']).ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score LR: 0.741514360313316\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0., 1., 0., ..., 1., 1., 0.])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logisticRegressionFullGridSearch(XT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multilayerPerceptron(props):\n",
    "    #mp_folds = 5\n",
    "    #mp_grid = dict(hidden_layer_sizes=[100], max_iter=[300], activation=['tanh'], solver=['sgd'], learning_rate=['constant'])\n",
    "    #clf = GridSearchCV(estimator=MLPClassifier(random_state=51), param_grid=mp_grid, n_jobs=-1, cv=mp_folds, scoring='f1', error_score=0)\n",
    "    #clf.fit(X_train, y_train)\n",
    "    clf = MLPClassifier(max_iter=props['max_iter'], hidden_layer_sizes=props['hidden_layer_sizes'], activation=props['activation'], solver=props['solver'])\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    #print(\"Best params:\", clf.best_params_)\n",
    "    \n",
    "    predicts = clf.predict(X_test)\n",
    "    print(\"Score Perceptron:\", f1_score(y_test, predicts))\n",
    "    \n",
    "    #generateSubmission(predicts, 'mlp_10l')\n",
    "    \n",
    "    #plt.ylabel('Loss')\n",
    "    #plt.xlabel('Iterations')\n",
    "    #plt.title(\"Loss Curve\")\n",
    "    #plt.plot(clf.loss_curve_)\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score Perceptron: 0.7659919028340082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Miniconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (800) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "multilayerPerceptron(dict(max_iter=800, hidden_layer_sizes=(35), activation='tanh', solver='sgd', alpha=10, learning_rate_init=23.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score Perceptron: 0.7071823204419889\n"
     ]
    }
   ],
   "source": [
    "multilayerPerceptron(dict(max_iter=800, hidden_layer_sizes=(35), activation='relu', solver='lbfgs', alpha=10, learning_rate_init=50))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knnGridSearch():\n",
    "    y = np.array(train['target'])\n",
    "    X_train, X_test, y_train, y_test = train_test_split(train_numeric, y, test_size=0.20)\n",
    "\n",
    "    scaler = StandardScaler(with_mean=False)\n",
    "    scaler.fit(X_train)\n",
    "\n",
    "    X_train_s = scaler.transform(X_train)\n",
    "    X_test_s = scaler.transform(X_test)\n",
    "    \n",
    "    knn_folds = 10\n",
    "    knn_grid = dict(n_neighbors=[175, 180, 185, 190], weights=['distance'], p=[2, 3])\n",
    "    clf = GridSearchCV(estimator=KNeighborsClassifier(algorithm='brute'), param_grid=knn_grid, cv=knn_folds, n_jobs=-1, scoring='f1', error_score=0)\n",
    "    clf.fit(X_train_s, y_train)\n",
    "    \n",
    "    predicts = clf.predict(X_test_s)\n",
    "    print(\"Score KNN: \", f1_score(y_test, predicts))\n",
    "    \n",
    "    print(\"Best params:\", clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score KNN:  0.6959517657192075\n",
      "Best params: {'n_neighbors': 180, 'p': 3, 'weights': 'distance'}\n"
     ]
    }
   ],
   "source": [
    "knnGridSearch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
