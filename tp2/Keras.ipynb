{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "#import plotly.express as px\n",
    "import tensorflow as tf\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('/home/joaquin/Desktop/Datos/tp2/train.csv')\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Procesamiento de datos\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_df['text'], train_df['target'], test_size=0.33,\n",
    "                                                  random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parametros\n",
    "epochs = 5\n",
    "maxlen = 40\n",
    "n_words = 300\n",
    "embedding_dim = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenizaci√≥n\n",
    "tokenizer = Tokenizer(num_words = n_words, oov_token = '<OOV>')\n",
    "\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "word_index = tokenizer.word_index\n",
    "sequences_train = tokenizer.texts_to_sequences(X_train)\n",
    "sequences_test = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "padded_train = pad_sequences(sequences_train, maxlen = maxlen, truncating = 'post')\n",
    "padded_test = pad_sequences(sequences_test, maxlen = maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.sequential.Sequential at 0x7f0500deac50>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#modelo\n",
    "model = tf.keras.Sequential([tf.keras.layers.Embedding(n_words,embedding_dim, input_length = maxlen),\n",
    "                             tf.keras.layers.Flatten(),\n",
    "                             tf.keras.layers.Dense(6, activation='relu'),\n",
    "                             tf.keras.layers.Dense(1, activation='sigmoid')])\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "160/160 [==============================] - 3s 18ms/step - loss: 0.6631 - accuracy: 0.5686 - val_loss: 0.6365 - val_accuracy: 0.6546\n",
      "Epoch 2/5\n",
      "160/160 [==============================] - 2s 15ms/step - loss: 0.6223 - accuracy: 0.6682 - val_loss: 0.6099 - val_accuracy: 0.7075\n",
      "Epoch 3/5\n",
      "160/160 [==============================] - 3s 18ms/step - loss: 0.5825 - accuracy: 0.7243 - val_loss: 0.5829 - val_accuracy: 0.7278\n",
      "Epoch 4/5\n",
      "160/160 [==============================] - 3s 16ms/step - loss: 0.5330 - accuracy: 0.7686 - val_loss: 0.5413 - val_accuracy: 0.7421\n",
      "Epoch 5/5\n",
      "160/160 [==============================] - 3s 16ms/step - loss: 0.4626 - accuracy: 0.7908 - val_loss: 0.5314 - val_accuracy: 0.7437\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f052ac90c10>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#entreno\n",
    "model.fit(padded_train, y_train, epochs=epochs, validation_data = (padded_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tuning: \n",
    "1-  epochs = 10\n",
    "    maxlen = 50\n",
    "    n_words = 500\n",
    "    embedding_dim = 16\n",
    "Acuracy: 0.7441\n",
    "\n",
    "2-  epochs = 6\n",
    "    maxlen = 40\n",
    "    n_words = 500\n",
    "    embedding_dim = 16\n",
    "Accuracy : 0.7656b\n",
    "\n",
    "3-  epochs = 5\n",
    "    maxlen = 40\n",
    "    n_words = 300\n",
    "    embedding_dim = 16\n",
    "Accuracy: 0.7437\n",
    "s"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
